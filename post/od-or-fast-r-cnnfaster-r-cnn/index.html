
<!DOCTYPE html>
<html>
  <head>
    
<meta charset="utf-8" >

<title>OD | Fast R-CNN、Faster R-CNN | one in a million</title>
<meta name="description" content="我在你的心里，有没有一点特别">

<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.7.0/animate.min.css">

<link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.7.2/css/all.css" integrity="sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr" crossorigin="anonymous">
<link rel="shortcut icon" href="https://wangfengyi0228.github.io/favicon.ico?v=1636720998486">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.10.0/katex.min.css">
<link rel="stylesheet" href="https://wangfengyi0228.github.io/styles/main.css">



<script src="https://cdn.jsdelivr.net/npm/vue/dist/vue.js"></script>
<script src="https://cdn.bootcss.com/highlight.js/9.12.0/highlight.min.js"></script>



  </head>
  <body>
    <div id="app" class="main">
      <div class="site-header-container">
  <div class="site-header">
    <div class="left">
      <a href="https://wangfengyi0228.github.io">
        <img class="avatar" src="https://wangfengyi0228.github.io/images/avatar.png?v=1636720998486" alt="" width="32px" height="32px">
      </a>
      <a href="https://wangfengyi0228.github.io">
        <h1 class="site-title">one in a million</h1>
      </a>
    </div>
    <div class="right">
      <transition name="fade">
        <i class="icon" :class="{ 'icon-close-outline': menuVisible, 'icon-menu-outline': !menuVisible }" @click="menuVisible = !menuVisible"></i>
      </transition>
    </div>
  </div>
</div>

<transition name="fade">
  <div class="menu-container" style="display: none;" v-show="menuVisible">
    <div class="menu-list">
      
        
          <a href="/" class="menu purple-link">
            首页
          </a>
        
      
        
          <a href="/archives" class="menu purple-link">
            归档
          </a>
        
      
        
          <a href="/tags" class="menu purple-link">
            标签
          </a>
        
      
        
          <a href="/post/about" class="menu purple-link">
            关于
          </a>
        
      
    </div>
  </div>
</transition>


      <div class="content-container">
        <div class="post-detail">
          
            <div class="feature-container" style="background-image: url('https://wangfengyi0228.github.io/post-images/od-or-fast-r-cnnfaster-r-cnn.jpg')">
            </div>
          
          <h2 class="post-title">OD | Fast R-CNN、Faster R-CNN</h2>
          <div class="post-info post-detail-info">
            <span><i class="icon-calendar-outline"></i> 2020-10-20</span>
            
              <span>
                <i class="icon-pricetags-outline"></i>
                
                  <a href="https://wangfengyi0228.github.io/tag/ON6Mm0HVp/">
                    Object Detection
                    
                      ，
                    
                  </a>
                
                  <a href="https://wangfengyi0228.github.io/tag/vYR76uwI3/">
                    Computer Vision
                    
                  </a>
                
              </span>
            
          </div>
          <div class="post-content">
            <p>#参考文献</p>
<ul>
<li>[1]Girshick R . Fast R-CNN[J]. Computer ence, 2015.</li>
<li>[2]Ren S , He K , Girshick R , et al. Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks[J]. IEEE Transactions on Pattern Analysis &amp; Machine Intelligence, 2017, 39(6):1137-1149.</li>
</ul>
<h1 id="1fast-r-cnn">1.Fast R-CNN</h1>
<p><strong>1.1概述</strong><br>
Fast R-CNN针对R-CNN以及SPP-net的不足进行了改进，将整个图像和一组object proposals作为输入。该网络首先用几个卷积层和max池化层处理整个图像，以生成feature map。然后，对于每一个object proposal，RoI层从feature map中提取一个固定长度的特征向量。每个特征向量被输入到一系列全连接层中，最后分为两个输出层：一个是分类的输出，另一个层为每个对象类输出四个实值数。每组4个值对其中一个类的精确边界框位置进行编码。为了实现端到端的训练，Fast R-CNN放弃了SVM分类器，而是选择微调后网络自身的softmax分类器。这样一来，特征提取，目标分类、候选框回归三部分可以同时进行端到端（end-to-end）训练。<br>
<img src="https://wangfengyi0228.github.io/post-images/1636706293347.png" alt="" loading="lazy"><br>
Fast R-CNN的流程图如上图所示，网络有两个输入：图像和对应的region proposal。其中region proposal由selective search方法得到。</p>
<p><strong>1.2 ROI pooling</strong><br>
ROI Pooling的作用是对不同大小的region proposal，从最后卷积层输出的feature map中提取大小固定的feature map。可以看做是SPPNet的简化版本，相当于只有一个金字塔层，因为全连接层的输入需要尺寸大小一样，所以不能直接将不同大小的region proposal映射到feature map作为输出，需要做尺寸变换。在文章中，VGG16网络使用H=W=7的参数，即将一个<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>h</mi><mo>∗</mo><mi>w</mi></mrow><annotation encoding="application/x-tex">h*w</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathdefault">h</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.02691em;">w</span></span></span></span>的region proposal分割成<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>H</mi><mo>∗</mo><mi>W</mi></mrow><annotation encoding="application/x-tex">H*W</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.08125em;">H</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">W</span></span></span></span>大小的网格，然后将这个region proposal映射到最后一个卷积层输出的feature map，最后计算每个网格里的最大值作为该网格的输出，所以不管ROI pooling之前的feature map大小是多少，ROI pooling后得到的feature map大小都是H*W。</p>
<p><strong>1.3 SVD分解改进全连接层</strong><br>
针对object detection，Fast R-CNN在ROI pooling后每个region proposal都要经过几个全连接层，这使得全连接层的计算占网络的计算将近一半，因此采用SVD来简化全连接层的计算。</p>
<p><strong>1.4优势与缺点</strong><br>
Fast R-CNN方法主要改进了RCNN的三个问题：一是测试时速度慢，RCNN一张图像内候选框之间大量重叠，提取特征操作冗余。Fast R-CNN对整张图像卷积而不是对每个region proposal卷积，损失函数使用了多任务损失函数(multi-task loss)，ROI Pooling，分类和回归都放在网络一起训练。二是训练时速度慢，Fast R-CNN在训练时，先将一张图像送入网络，紧接着送入从这幅图像上提取出的候选区域。这些候选区域的前几层特征不需要再重复计算。三是训练所需空间大，RCNN中独立的分类器和回归器需要大量特征作为训练样本,Fast R-CNN则把类别判断和位置精调统一用深度网络实现，不再需要额外存储。<br>
Fast R-CNN的主要缺点在于region proposal的提取仍然使用selective search，目标检测时间大多消耗在这上面。</p>
<h1 id="2faster-r-cnn">2.Faster R-CNN</h1>
<p><strong>2.1概述</strong><br>
<img src="https://wangfengyi0228.github.io/post-images/1636706543622.png" alt="" loading="lazy"><br>
如上图所示，Faster R-CNN主要可以分为以下四个内容：<br>
(1)Conv layers：作为一种CNN网络目标检测方法，Faster RCNN首先使用一组基础的conv+relu+pooling层提取image的feature maps。该feature maps被共享用于后续RPN层和全连接层。<br>
(2)Region Proposal Networks：RPN网络用于生成region proposals。该层通过softmax判断anchors属于positive或者negative，再利用bounding box regression修正anchors获得精确的proposals。<br>
(3)Roi Pooling：该层收集输入的feature maps和proposals，综合这些信息后提取proposal feature maps，送入后续全连接层判定目标类别。<br>
(4)Classification：利用proposal feature maps计算proposal的类别，同时再次bounding box regression获得检测框最终的精确位置。</p>
<p><strong>2.2 Conv layers</strong><br>
Conv layers包含了conv，pooling，relu三种层。以python版本中的VGG16模型中的faster_rcnn_test.pt的网络结构为例，Conv layers部分共有13个conv层，13个relu层，4个pooling层。在Conv layers中，所有的conv层都是：kernel_size=3，pad=1，stride=1；所有的pooling层都是：kernel_size=2，pad=0，stride=2。在Faster R-CNN的Conv layers中对所有的卷积都做了扩边处理（ pad=1，即填充一圈0），导致原图变为(M+2)<em>(N+2)大小，再做3x3卷积后输出MxN 。正是这种设置，导致Conv layers中的conv层不改变输入和输出矩阵大小。<br>
<img src="https://wangfengyi0228.github.io/post-images/1636707304609.png" alt="" loading="lazy"><br>
Conv layers中的pooling层kernel_size=2，stride=2。这样每个经过pooling层的MxN矩阵，都会变为<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mo>(</mo><mi>M</mi><mi mathvariant="normal">/</mi><mn>2</mn><mo>)</mo><mo>∗</mo><mo>(</mo><mi>N</mi><mi mathvariant="normal">/</mi><mn>2</mn><mo>)</mo></mrow><annotation encoding="application/x-tex">(M/2)*(N/2)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.10903em;">M</span><span class="mord">/</span><span class="mord">2</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.10903em;">N</span><span class="mord">/</span><span class="mord">2</span><span class="mclose">)</span></span></span></span>大小。综上所述，在整个Conv layers中，conv和relu层不改变输入输出大小，只有pooling层使输出长宽都变为输入的1/2。那么，一个MxN大小的矩阵经过Conv layers固定变为(M/16)</em>(N/16)，这样Conv layers生成的feature map中都可以和原图对应起来。</p>
<p><strong>2.3 Region Proposal Networks(RPN)</strong><br>
RPN以图像（任何大小）作为输入，并输出一组矩形object proposal，每个object proposal都有一个目标得分。</p>
<p><strong>2.3.1多通道图像卷积</strong><br>
<img src="https://wangfengyi0228.github.io/post-images/1636707348111.png" alt="" loading="lazy"><br>
如上图所示，输入有3个通道，同时有2个卷积核。对于每个卷积核，先在输入3个通道分别作卷积，再将3个通道结果加起来得到卷积输出。所以对于某个卷积层，无论输入图像有多少个通道，输出图像通道数总是等于卷积核数量。</p>
<p><strong>2.3.2 anchors</strong><br>
Anchors是一个个按照固定比例（长宽、大小）预定义的矩形框，由4个值(x1,x2,y1,y2) 表示矩形左上和右下角点坐标。9个矩形共有3种形状，长宽比为大约为{1:1, 1:2, 1:3}三种，如下图所示。实际上通过anchors就引入了检测中常用到的多尺度方法。<br>
<img src="https://wangfengyi0228.github.io/post-images/1636707391850.png" alt="" loading="lazy"><br>
遍历Conv layers计算获得的feature maps，为每一个点都配备这9种anchors作为初始的检测框。后面有2次bounding box regression可以修正检测框的位置。<br>
<img src="https://wangfengyi0228.github.io/post-images/1636707402081.png" alt="" loading="lazy"><br>
Conv Layers中最后的conv5层num_output=256，对应生成256张特征图，所以feature map每个点都是256-dimensions。在conv5之后，做了rpn_conv/3x3卷积且num_output=256，相当于每个点又融合了周围3x3的空间信息，同时256-d不变。假设在conv5 feature map中每个点上有k个anchor（默认k=9），而每个anhcor要分positive和negative，所以每个点由256d feature转化为cls=2k scores；而每个anchor都有(x, y, w, h)对应4个偏移量，所以reg=4k coordinates<br>
RPN最终就是在原图尺度上，设置了许多候选Anchor，用cnn去判断哪些Anchor是里面有目标的positive anchor，哪些是没目标的negative ancho，即一个二分类。原图大小为800x600，VGG下采样16倍，feature map每个点设置9个Anchor，所以anchor的个数为ceil(800/16)✖ceil(600/16)✖9=50✖38✖9=17100。<br>
<img src="https://wangfengyi0228.github.io/post-images/1636707439696.png" alt="" loading="lazy"><br>
<strong>2.3.3 softmax判定positive与negative</strong><br>
一个MxN大小的矩阵送入Faster RCNN网络后，到RPN网络变为(M/16)<em>(N/16)，假设W=M/16，H=N/16。在进入reshape与softmax之前，先做了1x1卷积，如图所示：<br>
<img src="https://wangfengyi0228.github.io/post-images/1636707464810.png" alt="" loading="lazy"><br>
经过该卷积的输出图像为W</em>H<em>18大小，刚好对应了feature maps每一个点都有9个anchors，同时每个anchors又有可能是positive和negative，所有这些信息都保存W</em>H*(9*2)大小的矩阵。后面softmax分类获得的positive anchors，相当于初步提取了检测目标候选区域box（一般认为目标在positive anchors中）。</p>
<p><strong>2.3.4 对proposals进行bounding box regression</strong><br>
在RPN的另一条线路中，经过该卷积输出图像为W<em>H</em>36，在caffe blob存储为[1, 4*9, H, W]，相当于feature maps的每个点都有9个anchors，每个anchors又都有4个用于回归的<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mo>[</mo><msub><mi>d</mi><mi>x</mi></msub><mo>(</mo><mi>A</mi><mo>)</mo><mo separator="true">,</mo><msub><mi>d</mi><mi>y</mi></msub><mo>(</mo><mi>A</mi><mo>)</mo><mo separator="true">,</mo><msub><mi>d</mi><mi>ω</mi></msub><mo>(</mo><mi>A</mi><mo>)</mo><mo separator="true">,</mo><msub><mi>d</mi><mi>h</mi></msub><mo>(</mo><mi>A</mi><mo>)</mo><mo>]</mo></mrow><annotation encoding="application/x-tex">[d_x(A),d_y(A),d_{\omega}(A),d_h(A)]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.036108em;vertical-align:-0.286108em;"></span><span class="mopen">[</span><span class="mord"><span class="mord mathdefault">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">x</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathdefault">A</span><span class="mclose">)</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.15139200000000003em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.03588em;">y</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathdefault">A</span><span class="mclose">)</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.03588em;">ω</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathdefault">A</span><span class="mclose">)</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">h</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathdefault">A</span><span class="mclose">)</span><span class="mclose">]</span></span></span></span><br>
<strong>2.3.5 Proposal Layer</strong><br>
Proposal Layer负责综合所有变换量和positive anchors，计算出精准的proposal，送入后续的RoI Pooling Layer。<br>
Proposal Layer有3个输入：anchors分类器结果rpn_cls_prob_reshape对应的bbox reg的 变换量rpn_bbox_pred；以及im_info；还有参数feat_stride=16。<br>
对于一副大小为PxQ的图像，传入Faster RCNN前首先reshape到固定的大小<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>M</mi><mo>∗</mo><mi>N</mi></mrow><annotation encoding="application/x-tex">M*N</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.10903em;">M</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.10903em;">N</span></span></span></span>，im_info=[M, N, scale_factor]保存了此次缩放的所有信息。然后经过Conv Layers，经过4次pooling变为<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>W</mi><mo>∗</mo><mi>H</mi><mo>=</mo><mo>(</mo><mi>M</mi><mi mathvariant="normal">/</mi><mn>16</mn><mo>)</mo><mo>∗</mo><mo>(</mo><mi>N</mi><mi mathvariant="normal">/</mi><mn>16</mn><mo>)</mo></mrow><annotation encoding="application/x-tex">W*H=(M/16)*(N/16)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">W</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.08125em;">H</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.10903em;">M</span><span class="mord">/</span><span class="mord">1</span><span class="mord">6</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.10903em;">N</span><span class="mord">/</span><span class="mord">1</span><span class="mord">6</span><span class="mclose">)</span></span></span></span>大小，其中feature_stride=16保存了该信息，用于计算anchor偏移量。</p>
<p><strong>2.4 RoI pooling</strong><br>
RoI Pooling层负责收集proposal，并计算出proposal feature maps，送入后续网络。Rol pooling层有2个输入：原始的feature maps、RPN输出的proposal boxes。</p>
<p><strong>2.5 Classification</strong><br>
Classification部分利用已经获得的proposal feature maps，通过全连接层与softmax计算每个proposal具体属于哪个类别，输出cls_prob概率向量；同时再次利用bounding box regression获得每个proposal的位置偏移量bbox_pred，用于回归更加精确的目标检测框。<br>
<img src="https://wangfengyi0228.github.io/post-images/1636707589866.png" alt="" loading="lazy"></p>
<h1 id="3总结">3.总结</h1>
<p><strong>(1)Fast R-CNN</strong><br>
Fast R-CNN借鉴了SPP-Net思路，提出了简化版的ROI池化层，同时加入了候选框映射功能，使得网络能够反向传播，并且用Softmax代替了SVM，Smooth L1 Loss取代了Bouding box回归。，采用SVD来简化全连接层的计算。<br>
其步骤可概括为：先寻找一个在imagenet上训练过的预训练cnn模型；与R-CNN一样，通过selective search在图片中提取2000个候选区域；将一整个图片都输入CNN模型中，提取到图片的整体特征；把候选区域映射到上一步CNN模型提取到的feature map里；采用rol pooling层对每个候选区域的特征进行上采样,从而得到固定大小的feature map,以便输入模型；根据Softmax loss和Smooth L1 Loss对候选区域的特征进行分类和回归调整，回归操作是对于框调整所使用的bounding box。如下图所示：<br>
<img src="https://wangfengyi0228.github.io/post-images/1636707627146.png" alt="" loading="lazy"></p>
<ul>
<li>
<p>优点：<br>
1.直接使用Softmax替代了R-CNN中SVM进行分类，同时在网络中加入了多任务函数边框回归。<br>
2.将分类和边框回归进行合并，通过多任务Loss层进一步整合深度网络，统一了训练过程， 从而提高了算法准确度。</p>
</li>
<li>
<p>缺点：<br>
1.region proposal的提取仍然使用selective search，目标检测时间大多消耗在这上面。</p>
</li>
</ul>
<p><strong>(2)Fster R-CNN</strong><br>
Faster-R-CNN算法由两大模块组成：RPN候选框提取模块和Fast R-CNN检测模块。其中，RPN是全卷积神经网络，用于提取候选框；Fast R-CNN基于RPN提取的region proposal检测并识别proposal中的目标。如下图所示：<br>
<img src="https://wangfengyi0228.github.io/post-images/1636707697459.png" alt="" loading="lazy"></p>
<ul>
<li>优点：<br>
1.提出Region Proposal Network（RPN），实现了一个完全的End-To-End的CNN目标检测模型。<br>
2.共享RPN与Fast R-CNN的特征。</li>
</ul>

          </div>
        </div>

        
          <div class="next-post">
            <a class="purple-link" href="https://wangfengyi0228.github.io/post/od-or-bounding-box-regression/">
              <h3 class="post-title">
                下一篇：OD | bounding box regression
              </h3>
            </a>
          </div>
          
      </div>

      

      <div class="site-footer">
  <div class="slogan">我在你的心里，有没有一点特别</div>
  <div class="social-container">
    
      
    
      
    
      
    
      
    
      
    
  </div>
  Copyright by WFY | <a class="rss" href="https://wangfengyi0228.github.io/atom.xml" target="_blank">RSS</a>
</div>


    </div>
    <script type="application/javascript">

hljs.initHighlightingOnLoad()

var app = new Vue({
  el: '#app',
  data: {
    menuVisible: false,
  },
})

</script>




  </body>
</html>
