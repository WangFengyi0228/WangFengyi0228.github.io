
<!DOCTYPE html>
<html>
  <head>
    
<meta charset="utf-8" >

<title>ML | 梯度下降法（Gradient Descent） | one in a million</title>
<meta name="description" content="我在你的心里，有没有一点特别">

<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.7.0/animate.min.css">

<link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.7.2/css/all.css" integrity="sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr" crossorigin="anonymous">
<link rel="shortcut icon" href="https://wangfengyi0228.github.io/favicon.ico?v=1636788764595">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.10.0/katex.min.css">
<link rel="stylesheet" href="https://wangfengyi0228.github.io/styles/main.css">



<script src="https://cdn.jsdelivr.net/npm/vue/dist/vue.js"></script>
<script src="https://cdn.bootcss.com/highlight.js/9.12.0/highlight.min.js"></script>



  </head>
  <body>
    <div id="app" class="main">
      <div class="site-header-container">
  <div class="site-header">
    <div class="left">
      <a href="https://wangfengyi0228.github.io">
        <img class="avatar" src="https://wangfengyi0228.github.io/images/avatar.png?v=1636788764595" alt="" width="32px" height="32px">
      </a>
      <a href="https://wangfengyi0228.github.io">
        <h1 class="site-title">one in a million</h1>
      </a>
    </div>
    <div class="right">
      <transition name="fade">
        <i class="icon" :class="{ 'icon-close-outline': menuVisible, 'icon-menu-outline': !menuVisible }" @click="menuVisible = !menuVisible"></i>
      </transition>
    </div>
  </div>
</div>

<transition name="fade">
  <div class="menu-container" style="display: none;" v-show="menuVisible">
    <div class="menu-list">
      
        
          <a href="/" class="menu purple-link">
            首页
          </a>
        
      
        
          <a href="/archives" class="menu purple-link">
            归档
          </a>
        
      
        
          <a href="/tags" class="menu purple-link">
            标签
          </a>
        
      
        
          <a href="/post/about" class="menu purple-link">
            关于
          </a>
        
      
    </div>
  </div>
</transition>


      <div class="content-container">
        <div class="post-detail">
          
            <div class="feature-container" style="background-image: url('https://wangfengyi0228.github.io/post-images/ml-or-ti-du-xia-jiang-fa-gradient-descent.jpg')">
            </div>
          
          <h2 class="post-title">ML | 梯度下降法（Gradient Descent）</h2>
          <div class="post-info post-detail-info">
            <span><i class="icon-calendar-outline"></i> 2019-06-26</span>
            
              <span>
                <i class="icon-pricetags-outline"></i>
                
                  <a href="https://wangfengyi0228.github.io/tag/WBQki2hdM/">
                    Machine Learning
                    
                  </a>
                
              </span>
            
          </div>
          <div class="post-content">
            <h1 id="1梯度">1.梯度</h1>
<p>在微积分里面，对多元函数的参数求∂偏导数，把求得的各个参数的偏导数以向量的形式写出来，就是梯度。梯度的意义从几何意义上讲，就是函数变化增加最快的地方，或者说，沿着梯度向量的方向，更加容易找到函数的最大值。反过来说，沿着梯度向量相反的方向，梯度减少最快，也就是更加容易找到函数的最小值。</p>
<h1 id="2梯度上升与梯度下降">2.梯度上升与梯度下降</h1>
<p>在机器学习算法中，在最小化损失函数时，可以通过梯度下降法来一步步的迭代求解，得到最小化的损失函数，和模型参数值。反过来，如果需要求解损失函数的最大值，这时就需要用梯度上升法来迭代了。<br>
梯度下降法和梯度上升法是可以互相转化的。比如需要求解损失函数f(θ)的最小值，这时我们需要用梯度下降法来迭代求解。但是实际上，可以反过来求解损失函数 -f(θ)的最大值，这时就可以用梯度上升法。</p>
<h1 id="3相关概念">3.相关概念</h1>
<figure data-type="image" tabindex="1"><img src="https://wangfengyi0228.github.io/post-images/1636714177723.png" alt="" loading="lazy"></figure>
<h1 id="4算法过程">4.算法过程</h1>
<figure data-type="image" tabindex="2"><img src="https://wangfengyi0228.github.io/post-images/1636714211393.png" alt="" loading="lazy"></figure>
<h1 id="5梯度下降法分类">5.梯度下降法分类</h1>
<p><strong>5.1批量梯度下降法（Batch Gradient Descent）</strong><br>
批量梯度下降法，是梯度下降法最常用的形式，具体做法也就是在更新参数时使用所有的样本来进行更新，上文的梯度下降算法就是批量梯度下降法。对应的更新公式为：<br>
<img src="https://wangfengyi0228.github.io/post-images/1636714251437.png" alt="" loading="lazy"><br>
当有m个样本时，求梯度的时候就用了所有m个样本的梯度数据。</p>
<p><strong>5.2随机梯度下降法（Stochastic Gradient Descent）</strong><br>
随机梯度下降法求梯度时没有用所有的m个样本的数据，而是仅仅选取一个样本j来求梯度。对应的更新公式是：<br>
<img src="https://wangfengyi0228.github.io/post-images/1636714280594.png" alt="" loading="lazy"><br>
对于训练速度来说，随机梯度下降法由于每次仅仅采用一个样本来迭代，训练速度很快，而批量梯度下降法在样本量很大的时候，训练速度不能让人满意。对于准确度来说，随机梯度下降法用于仅仅用一个样本决定梯度方向，导致解很有可能不是最优。对于收敛速度来说，由于随机梯度下降法一次迭代一个样本，导致迭代方向变化很大，不能很快的收敛到局部最优解。</p>
<p><strong>5.3小批量梯度下降法（Mini-batch Gradient Descent）</strong><br>
小批量梯度下降法是批量梯度下降法和随机梯度下降法的折中，也就是对于m个样本，我们采用x个样子来迭代，1&lt;x&lt;m。一般可以取x=10，当然根据样本的数据，可以调整这个x的值。对应的更新公式是：<br>
<img src="https://wangfengyi0228.github.io/post-images/1636714314738.png" alt="" loading="lazy"></p>

          </div>
        </div>

        
          <div class="next-post">
            <a class="purple-link" href="https://wangfengyi0228.github.io/post/movies-or-ran-shao/">
              <h3 class="post-title">
                下一篇：Movies | 燃烧
              </h3>
            </a>
          </div>
          
      </div>

      

      <div class="site-footer">
  <div class="slogan">我在你的心里，有没有一点特别</div>
  <div class="social-container">
    
      
    
      
    
      
    
      
    
      
    
  </div>
  Copyright by WFY | <a class="rss" href="https://wangfengyi0228.github.io/atom.xml" target="_blank">RSS</a>
</div>


    </div>
    <script type="application/javascript">

hljs.initHighlightingOnLoad()

var app = new Vue({
  el: '#app',
  data: {
    menuVisible: false,
  },
})

</script>




  </body>
</html>
